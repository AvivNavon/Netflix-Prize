{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Learning \n",
    "\n",
    "## Class Competition: Netflix Data\n",
    "\n",
    "## Predictions\n",
    "\n",
    " - Week 1: we had an error in script\n",
    " - Week 2: we used 2.5 for null values, prediction using Lasso + GBM\n",
    " - Week 3: $$user\\_avg \\cdot user\\_prop + movie\\_avg \\cdot (1-user\\_prop) - penalty$$ for nulls.\n",
    " - Week 4: Add some more features. 0.7 * lasso + 0.3 * gbm (+ bug fix from prior week)...\n",
    " - Week 5: Ensamble model.\n",
    " \n",
    "\n",
    "# Navigation\n",
    "\n",
    "1. [Get Data](#Get-Data)\n",
    "1. [New Features](#New-Features)\n",
    "1. [Fix Nulls](#Fix-Nulls)\n",
    "1. [Netflix Class](#Netflix-Class)\n",
    "1. [Modeling](#Modeling)\n",
    "1. [Prediction](#Prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.cluster import KMeans\n",
    " \n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# from sklearn.preprocessing import Imputer\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "# from sklearn.decomposition import NMF\n",
    "# from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# from surprise import evaluate, print_perf, Dataset\n",
    "# from surprise import SVD, SVDpp\n",
    "\n",
    "import time\n",
    "\n",
    "from ggplot import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data\n",
    "\n",
    "[Top](#Navigation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>title</th>\n",
       "      <th>Independence Day</th>\n",
       "      <th>The Patriot</th>\n",
       "      <th>The Day After Tomorrow</th>\n",
       "      <th>Pirates of the Caribbean: The Curse of the Black Pearl</th>\n",
       "      <th>Pretty Woman</th>\n",
       "      <th>Forrest Gump</th>\n",
       "      <th>The Green Mile</th>\n",
       "      <th>Con Air</th>\n",
       "      <th>Twister</th>\n",
       "      <th>Sweet Home Alabama</th>\n",
       "      <th>...</th>\n",
       "      <th>Somethings Gotta Give</th>\n",
       "      <th>Raiders of the Lost Ark</th>\n",
       "      <th>Anger Management</th>\n",
       "      <th>Sideways</th>\n",
       "      <th>Kill Bill: Vol. 2</th>\n",
       "      <th>American Pie</th>\n",
       "      <th>The Fast and the Furious</th>\n",
       "      <th>The School of Rock</th>\n",
       "      <th>Napoleon Dynamite</th>\n",
       "      <th>The Notebook</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 99 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "title  Independence Day  The Patriot  The Day After Tomorrow  \\\n",
       "0                     4            4                       3   \n",
       "1                     4            5                       3   \n",
       "2                     5            5                       5   \n",
       "3                     5            5                       5   \n",
       "4                     5            5                       5   \n",
       "\n",
       "title  Pirates of the Caribbean: The Curse of the Black Pearl  Pretty Woman  \\\n",
       "0                                                      5                  4   \n",
       "1                                                      3                  4   \n",
       "2                                                      5                  4   \n",
       "3                                                      5                  4   \n",
       "4                                                      5                  5   \n",
       "\n",
       "title  Forrest Gump  The Green Mile  Con Air  Twister  Sweet Home Alabama  \\\n",
       "0                 5               4        4        5                   4   \n",
       "1                 3               4        4        3                   2   \n",
       "2                 5               4        3        4                   5   \n",
       "3                 5               5        3        4                   5   \n",
       "4                 5               5        5        5                   5   \n",
       "\n",
       "title      ...       Somethings Gotta Give  Raiders of the Lost Ark  \\\n",
       "0          ...                           5                        5   \n",
       "1          ...                           4                        4   \n",
       "2          ...                           5                        4   \n",
       "3          ...                           4                        5   \n",
       "4          ...                           3                        0   \n",
       "\n",
       "title  Anger Management  Sideways  Kill Bill: Vol. 2  American Pie  \\\n",
       "0                     4         4                  5             5   \n",
       "1                     3         2                  3             3   \n",
       "2                     4         0                  0             5   \n",
       "3                     5         4                  4             2   \n",
       "4                     3         0                  2             4   \n",
       "\n",
       "title  The Fast and the Furious  The School of Rock  Napoleon Dynamite  \\\n",
       "0                             5                   5                  0   \n",
       "1                             0                   3                  3   \n",
       "2                             5                   0                  0   \n",
       "3                             4                   2                  2   \n",
       "4                             5                   4                  0   \n",
       "\n",
       "title  The Notebook  \n",
       "0                 4  \n",
       "1                 5  \n",
       "2                 0  \n",
       "3                 0  \n",
       "4                 5  \n",
       "\n",
       "[5 rows x 99 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read data\n",
    "X_train = pd.read_csv(\"Data/X_train.csv\")\n",
    "X_train_dates = pd.read_csv(\"Data/X_train_dates.csv\")\n",
    "y_train_dates = pd.read_csv(\"Data/y_train_dates.csv\")\n",
    "y_train_full = pd.read_csv(\"Data/y_train.csv\")\n",
    "\n",
    "X_test = pd.read_csv(\"Data/X_test.csv\")\n",
    "X_test_dates = pd.read_csv(\"Data/X_test_dates.csv\")\n",
    "y_test_dates = pd.read_csv(\"Data/y_test_dates.csv\")\n",
    "\n",
    "titles = pd.read_csv(\"Data/titles.csv\")\n",
    "\n",
    "# col names\n",
    "titles.columns = ['date', 'title']\n",
    "X_train.columns = titles.title\n",
    "X_train_dates.columns = titles.title\n",
    "X_test.columns = titles.title\n",
    "X_test_dates.columns = titles.title\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Features\n",
    "\n",
    "[Top](#Navigatin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def new_features(ratings_df, dates_df, y_dates, na_val = 2.5):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    df = ratings_df.copy()\n",
    "    number_of_ratings_per_user = ratings_df.apply(lambda x : sum(x != 0), axis = 1)\n",
    "    avg_of_ratings_per_user = ratings_df.apply(lambda x : np.mean(x[x != 0]), axis = 1)\n",
    "    median_of_ratings_per_user = ratings_df.apply(lambda x : np.median(x[x != 0]), axis = 1)\n",
    "    sd_of_ratings_per_user = ratings_df.apply(lambda x : np.std(x[x != 0]), axis = 1)\n",
    "    days_since_first_rating = y_dates.V1 - dates_df.apply(lambda x : min(x[x != 0]), axis = 1) \n",
    "\n",
    "    avg_ratings_before = []\n",
    "    num_ratings_before = []\n",
    "    avg_ratings_after = []\n",
    "    num_ratings_after = []\n",
    "\n",
    "    for i in range(ratings_df.shape[0]):\n",
    "        tmp_b = ratings_df.iloc[i][(dates_df.iloc[i] <= y_dates.iloc[i].V1)]\n",
    "        tmp_a = ratings_df.iloc[i][(dates_df.iloc[i] > y_dates.iloc[i].V1)]\n",
    "        avg_ratings_before.append(np.mean(tmp_b[tmp_b != 0]))\n",
    "        avg_ratings_after.append(np.mean(tmp_a[tmp_a != 0]))\n",
    "        num_ratings_before.append(sum(tmp_b != 0))\n",
    "        num_ratings_after.append(sum(tmp_a != 0))\n",
    "    \n",
    "    df['y_dates'] = y_dates.V1\n",
    "    \n",
    "    df['number_of_ratings_per_user'] = number_of_ratings_per_user\n",
    "    df['avg_of_ratings_per_user'] = avg_of_ratings_per_user\n",
    "    df['median_of_ratings_per_user'] = median_of_ratings_per_user\n",
    "    df['sd_of_ratings_per_user'] = sd_of_ratings_per_user\n",
    "    df['days_since_first_rating'] = days_since_first_rating\n",
    "\n",
    "    df['avg_ratings_before'] = avg_ratings_before\n",
    "    df['num_ratings_before'] = num_ratings_before\n",
    "    df['avg_ratings_after'] = avg_ratings_after\n",
    "    df['num_ratings_after'] = num_ratings_after\n",
    "\n",
    "    df.fillna(na_val, inplace = True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix Nulls\n",
    "\n",
    "[Top](#Navigation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def na_fix(df, prop_user, penalty, cols):\n",
    "    \"\"\"\n",
    "    Fill null values with avg_rating_user * prop_user + avg_rating_movie * (1 - prop_user) - penalty\n",
    "    \"\"\"\n",
    "    avg_rating_per_movie = df[cols].replace(0, np.nan).mean(skipna = True)\n",
    "    avg_rating_per_user = df[cols].apply(lambda x : np.mean(x[x != 0]), axis = 1)\n",
    "    \n",
    "    na_fix = df.copy()\n",
    "    for column in cols:\n",
    "        na_fix[column] = avg_rating_per_user * prop_user + avg_rating_per_movie[column] * (1 - prop_user) - penalty\n",
    "        \n",
    "    df_imp = df.copy()\n",
    "    df_imp = df_imp.where(df_imp[cols] != 0, na_fix[cols]) # fill zeros with new values...\n",
    "    \n",
    "    return df_imp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Netflix Class\n",
    "\n",
    "All model's and methods...\n",
    "\n",
    "[Top](#Navigation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NetflixPrize:\n",
    "    \"\"\"\n",
    "    Main class for modeling and prediction \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, X_train, y_train, X_test, y_test = None, use_residuals = False, cv = 5):\n",
    "        \"\"\"\n",
    "        Initialize ensamble model\n",
    "        \"\"\"\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train.values.ravel()\n",
    "        self.X_test = X_test\n",
    "        if y_test is not None:\n",
    "            self.y_test = y_test.values.ravel()\n",
    "        else:\n",
    "            self.y_test = None\n",
    "        self.use_residuals = use_residuals\n",
    "        self.cv = cv\n",
    "        \n",
    "    #####################\n",
    "    # General Functions #\n",
    "    #####################\n",
    "    \n",
    "    def rmse_calc(self, true, pred):\n",
    "        \"\"\"\n",
    "        Calculate RMSE\n",
    "        \"\"\"\n",
    "        return np.sqrt(mean_squared_error(true, pred))\n",
    "    \n",
    "    def get_residuals(self, true, pred):\n",
    "        \"\"\"\n",
    "        Get residuals\n",
    "        \"\"\"\n",
    "        return true - pred\n",
    "        \n",
    "   \n",
    "    #########\n",
    "    # Lasso #\n",
    "    #########\n",
    "    \n",
    "    def lasso_cv_model(self, n_alphas = 200, max_iter = 5000, normalize = True):\n",
    "        \"\"\"\n",
    "        Initialize Lasso model\n",
    "        \"\"\"\n",
    "        self.lasso_cv_model_ = LassoCV(n_alphas = n_alphas, max_iter = max_iter, normalize = normalize)\n",
    "        return self.lasso_cv_model_\n",
    "    \n",
    "    def lasso_cv_fit(self, X_train, y_train, \n",
    "                     n_alphas = 200, max_iter = 5000, normalize = True):\n",
    "        \"\"\"\n",
    "        Fit Lasso model\n",
    "        \"\"\"\n",
    "        lasso_mod = self.lasso_cv_model(n_alphas = n_alphas, max_iter = max_iter, normalize = normalize)\n",
    "        self.lasso_cv_fit_ = lasso_mod.fit(X_train, y_train)\n",
    "        return self.lasso_cv_fit_\n",
    "    \n",
    "    def lasso_cv_predict(self, X_train, y_train, X_test, \n",
    "                         n_alphas = 200, max_iter = 5000, normalize = True):\n",
    "        \"\"\"\n",
    "        Predict using Lasso\n",
    "        \"\"\"\n",
    "        lasso_fit = self.lasso_cv_fit(X_train, y_train, n_alphas = n_alphas, \n",
    "                                      max_iter = max_iter, normalize = normalize)\n",
    "        self.lasso_pred_ = lasso_fit.predict(X_test)\n",
    "        \n",
    "        # fix\n",
    "        self.lasso_pred_[self.lasso_pred_ < 1] = 1\n",
    "        self.lasso_pred_[self.lasso_pred_ > 5] = 5\n",
    "        \n",
    "        return self.lasso_pred_\n",
    "    \n",
    "    #######\n",
    "    # GBM #\n",
    "    #######\n",
    "    \n",
    "    def gbm_model(self, learning_rate = .025, n_estimators = 400):\n",
    "        \"\"\"\n",
    "        Initialize GBM model\n",
    "        \"\"\"\n",
    "        self.gbm_model_ = GradientBoostingRegressor(learning_rate = learning_rate, n_estimators = n_estimators)\n",
    "        return self.gbm_model_\n",
    "    \n",
    "    def gbm_fit(self, X_train, y_train, learning_rate = .025, n_estimators = 400):\n",
    "        \"\"\"\n",
    "        Fit GBM model\n",
    "        \"\"\"\n",
    "        gbm_mod = self.gbm_model(learning_rate = learning_rate, n_estimators = n_estimators)\n",
    "        self.gbm_fit_ = gbm_mod.fit(X_train, y_train)\n",
    "        return self.gbm_fit_\n",
    "    \n",
    "    def gbm_predict(self, X_train, y_train, X_test, \n",
    "                    learning_rate = .025, n_estimators = 400):\n",
    "        \"\"\"\n",
    "        Predict using GBM\n",
    "        \"\"\"\n",
    "        gbm_fit = self.gbm_fit(X_train, y_train, learning_rate = learning_rate, n_estimators = n_estimators)\n",
    "        self.gbm_pred_ = gbm_fit.predict(X_test)\n",
    "        \n",
    "        # fix\n",
    "        self.gbm_pred_[self.gbm_pred_ < 1] = 1\n",
    "        self.gbm_pred_[self.gbm_pred_ > 5] = 5\n",
    "        \n",
    "        return self.gbm_pred_\n",
    "    \n",
    "    ######\n",
    "    # RF #\n",
    "    ######\n",
    "    \n",
    "    def rf_model(self, n_estimators = 100):\n",
    "        \"\"\"\n",
    "        Initialize RF model\n",
    "        \"\"\"\n",
    "        self.rf_model_ = RandomForestRegressor(n_estimators = n_estimators)\n",
    "        return self.rf_model_\n",
    "    \n",
    "    def rf_fit(self, X_train, y_train, n_estimators = 100):\n",
    "        \"\"\"\n",
    "        Fit RF model\n",
    "        \"\"\"\n",
    "        rf_mod = self.rf_model(n_estimators = n_estimators)\n",
    "        self.rf_fit_ = rf_mod.fit(X_train, y_train)\n",
    "        return self.rf_fit_\n",
    "    \n",
    "    def rf_predict(self, X_train, y_train, X_test, n_estimators = 100):\n",
    "        \"\"\"\n",
    "        Predict using RF\n",
    "        \"\"\"\n",
    "        rf_fit = self.rf_fit(X_train, y_train, n_estimators = n_estimators)\n",
    "        self.rf_pred_ = rf_fit.predict(X_test)\n",
    "        \n",
    "        # fix\n",
    "        self.rf_pred_[self.rf_pred_ < 1] = 1\n",
    "        self.rf_pred_[self.rf_pred_ > 5] = 5\n",
    "        \n",
    "        return self.rf_pred_\n",
    "    \n",
    "    #######\n",
    "    # PCA #\n",
    "    #######\n",
    "    \n",
    "    def pca_model(self, n_components = 10):\n",
    "        \"\"\"\n",
    "        Fit PCA\n",
    "        \"\"\"\n",
    "        self.pca_model_ = PCA(n_components = n_components)\n",
    "        \n",
    "        return self.pca_model_\n",
    "    \n",
    "    def pca_fit(self, df_fit, n_components = 10):\n",
    "        \"\"\"\n",
    "        Fit PCA\n",
    "        \"\"\"\n",
    "        pca_model = PCA(n_components = n_components)\n",
    "        self.pca_fit_ = pca_model.fit(df_fit)\n",
    "        \n",
    "        return self.pca_fit_\n",
    "            \n",
    "    \n",
    "    def pca_transform(self, df_transform, df_fit = None, n_components = 10, scale = True):\n",
    "        \"\"\"\n",
    "        PCA transform\n",
    "        \"\"\"\n",
    "        if df_fit is None:\n",
    "            df_fit = df_transform.copy()\n",
    "            \n",
    "        if scale:\n",
    "            scale = StandardScaler()\n",
    "            scale_fit = scale.fit(df_fit)\n",
    "            df_fit = scale_fit.transform(df_fit)\n",
    "            df_transform = scale_fit.transform(df_transform)\n",
    "            \n",
    "        pca_fit = self.pca_fit(df_fit, n_components = n_components)\n",
    "        pca_df = pca_fit.transform(df_transform)\n",
    "        \n",
    "        return pca_df\n",
    "    \n",
    "    ########\n",
    "    # k-NN #\n",
    "    ########\n",
    "    \n",
    "    def knn_model(self, n_neighbors = 100, weights = 'distance', p = 1):\n",
    "        \"\"\"\n",
    "        Initialize k-NN model\n",
    "        \"\"\"\n",
    "        self.knn_model_ = KNeighborsRegressor(n_neighbors = n_neighbors, weights = weights, p = p)\n",
    "        \n",
    "        return self.knn_model_\n",
    "    \n",
    "    def knn_fit(self, X_train, y_train, n_neighbors = 100, weights = 'distance', p = 1):\n",
    "        \"\"\"\n",
    "        Fit k-NN model\n",
    "        \"\"\"\n",
    "        knn_model = self.knn_model(n_neighbors = n_neighbors, weights = weights, p = p)\n",
    "        self.knn_fit_ = knn_model.fit(X_train, y_train)\n",
    "        \n",
    "        return self.knn_fit_\n",
    "    \n",
    "    def knn_predict(self, X_train, y_train, X_test, n_neighbors = 100, weights = 'distance', p = 1):\n",
    "        \"\"\"\n",
    "        Predict using k-NN\n",
    "        \"\"\"\n",
    "        knn_fit = self.knn_fit(X_train, y_train, n_neighbors = n_neighbors, weights = weights, p = p)\n",
    "        self.knn_pred_ = knn_fit.predict(X_test)\n",
    "        \n",
    "        # fix\n",
    "        self.knn_pred_[self.knn_pred_ < 1] = 1\n",
    "        self.knn_pred_[self.knn_pred_ > 5] = 5\n",
    "        \n",
    "        return self.knn_pred_\n",
    "    \n",
    "    ##################\n",
    "    # ensamble model #\n",
    "    ##################\n",
    "    \n",
    "    def ensamble_model_fit_predict(self, X_train, y_train, X_val, y_val, X_test):\n",
    "        \"\"\"\n",
    "        Fit an ensamble model\n",
    "        \"\"\"\n",
    "        # PCA\n",
    "        # 10 components\n",
    "#         pca_X_train_10 = self.pca_transform(X_train)\n",
    "#         pca_X_val_10 = self.pca_transform(X_val, X_train)\n",
    "#         pca_X_test_10 = self.pca_transform(X_test, X_train)\n",
    "        # 40 components\n",
    "        pca_X_train_40 = self.pca_transform(X_train, n_components = 40)\n",
    "        pca_X_val_40 = self.pca_transform(X_val, X_train, n_components = 40)\n",
    "        pca_X_test_40 = self.pca_transform(X_test, X_train, n_components = 40)\n",
    "        # k-NN\n",
    "#         knn_val_pred = self.knn_predict(pca_X_train_10, y_train, pca_X_val_10)\n",
    "#         knn_test_pred = self.knn_predict(pca_X_train_10, y_train, pca_X_test_10)\n",
    "        # lasso\n",
    "        lasso_val_pred = self.lasso_cv_predict(X_train, y_train, X_val)\n",
    "        lasso_test_pred = self.lasso_cv_predict(X_train, y_train, X_test)\n",
    "        # lasso PCA\n",
    "        lasso_val_pca_pred = self.lasso_cv_predict(pca_X_train_40, y_train, pca_X_val_40)\n",
    "        lasso_test_pca_pred = self.lasso_cv_predict(pca_X_train_40, y_train, pca_X_test_40)\n",
    "        # rf pred\n",
    "        rf_val_pred = self.rf_predict(X_train, y_train, X_val)\n",
    "        rf_test_pred = self.rf_predict(X_train, y_train, X_test)\n",
    "        # rf pred PCA\n",
    "        rf_val_pca_pred = self.rf_predict(pca_X_train_40, y_train, pca_X_val_40)\n",
    "        rf_test_pca_pred = self.rf_predict(pca_X_train_40, y_train, pca_X_test_40)\n",
    "        # gbm pred\n",
    "        gbm_val_pred = self.gbm_predict(X_train, y_train, X_val)\n",
    "        gbm_test_pred = self.gbm_predict(X_train, y_train, X_test)\n",
    "        # gbm pred PCA\n",
    "        gbm_val_pca_pred = self.gbm_predict(pca_X_train_40, y_train, pca_X_val_40)\n",
    "        gbm_test_pca_pred = self.gbm_predict(pca_X_train_40, y_train, pca_X_test_40)\n",
    "        # all\n",
    "        all_val_pred = pd.DataFrame({#'knn':knn_val_pred, \n",
    "                                     'lasso':lasso_val_pred, \n",
    "                                     'rf':rf_val_pred, 'gbm':gbm_val_pred, \n",
    "                                     'lasso_pca':lasso_val_pca_pred, 'rf_pca':rf_val_pca_pred,\n",
    "                                     'gbm_pca':gbm_val_pca_pred})\n",
    "\n",
    "        all_test_pred = pd.DataFrame({#'knn':knn_test_pred, \n",
    "                                      'lasso':lasso_test_pred, \n",
    "                                      'rf':rf_test_pred, 'gbm':gbm_test_pred, \n",
    "                                      'lasso_pca':lasso_test_pca_pred, 'rf_pca':rf_test_pca_pred,\n",
    "                                      'gbm_pca':gbm_test_pca_pred})\n",
    "        # final model\n",
    "        final_lasso_pred = self.lasso_cv_predict(all_val_pred, y_val, all_test_pred)\n",
    "#         final_elastic_pred = ElasticNetCV(normalize = True).fit(all_val_pred, y_val).predict(all_test_pred) # tmp\n",
    "        return final_lasso_pred\n",
    "\n",
    "    def ensamble_model_fit_predict_no_val(self, X_train, y_train, X_test):\n",
    "        \"\"\"\n",
    "        Fit an ensamble model\n",
    "        \"\"\"\n",
    "        # PCA\n",
    "        # 10 components\n",
    "#         pca_X_train_10 = self.pca_transform(X_train)\n",
    "#         pca_X_val_10 = self.pca_transform(X_val, X_train)\n",
    "#         pca_X_test_10 = self.pca_transform(X_test, X_train)\n",
    "        # 40 components\n",
    "        pca_X_train_40 = self.pca_transform(X_train, n_components = 40)\n",
    "#         pca_X_val_40 = self.pca_transform(X_val, X_train, n_components = 40)\n",
    "        pca_X_test_40 = self.pca_transform(X_test, X_train, n_components = 40)\n",
    "        # k-NN\n",
    "#         knn_val_pred = self.knn_predict(pca_X_train_10, y_train, pca_X_val_10)\n",
    "#         knn_test_pred = self.knn_predict(pca_X_train_10, y_train, pca_X_test_10)\n",
    "        # lasso\n",
    "        lasso_train_pred = self.lasso_cv_predict(X_train, y_train, X_train)\n",
    "        lasso_test_pred = self.lasso_cv_predict(X_train, y_train, X_test)\n",
    "        # lasso PCA\n",
    "        lasso_train_pca_pred = self.lasso_cv_predict(pca_X_train_40, y_train, pca_X_train_40)\n",
    "        lasso_test_pca_pred = self.lasso_cv_predict(pca_X_train_40, y_train, pca_X_test_40)\n",
    "        # rf pred\n",
    "        rf_train_pred = self.rf_predict(X_train, y_train, X_train)\n",
    "        rf_test_pred = self.rf_predict(X_train, y_train, X_test)\n",
    "        # rf pred PCA\n",
    "        rf_train_pca_pred = self.rf_predict(pca_X_train_40, y_train, pca_X_train_40)\n",
    "        rf_test_pca_pred = self.rf_predict(pca_X_train_40, y_train, pca_X_test_40)\n",
    "        # gbm pred\n",
    "        gbm_train_pred = self.gbm_predict(X_train, y_train, X_train)\n",
    "        gbm_test_pred = self.gbm_predict(X_train, y_train, X_test)\n",
    "        # gbm pred PCA\n",
    "        gbm_train_pca_pred = self.gbm_predict(pca_X_train_40, y_train, pca_X_train_40)\n",
    "        gbm_test_pca_pred = self.gbm_predict(pca_X_train_40, y_train, pca_X_test_40)\n",
    "        # all\n",
    "        all_train_pred = pd.DataFrame({#'knn':knn_train_pred, \n",
    "                                     'lasso':lasso_train_pred, \n",
    "                                     'rf':rf_train_pred, 'gbm':gbm_train_pred, \n",
    "                                     'lasso_pca':lasso_train_pca_pred, 'rf_pca':rf_train_pca_pred,\n",
    "                                     'gbm_pca':gbm_train_pca_pred})\n",
    "\n",
    "        all_test_pred = pd.DataFrame({#'knn':knn_test_pred, \n",
    "                                      'lasso':lasso_test_pred, \n",
    "                                      'rf':rf_test_pred, 'gbm':gbm_test_pred, \n",
    "                                      'lasso_pca':lasso_test_pca_pred, 'rf_pca':rf_test_pca_pred,\n",
    "                                      'gbm_pca':gbm_test_pca_pred})\n",
    "        # final model\n",
    "        final_lasso_pred = self.lasso_cv_predict(all_train_pred, y_train, all_test_pred)\n",
    "#         final_elastic_pred = ElasticNetCV(normalize = True).fit(all_val_pred, y_val).predict(all_test_pred) # tmp\n",
    "        return final_lasso_pred\n",
    "    \n",
    "    def ensamble_rmse_cv(self, X_train, y_train, cv = 10, seed = 123):\n",
    "        \"\"\"\n",
    "        Estimate ensamble's model RMSE using CV\n",
    "        \"\"\"\n",
    "        data = X_train.copy()\n",
    "        data['response'] = y_train\n",
    "\n",
    "        random_ind = data.index.tolist()\n",
    "        np.random.seed(seed)\n",
    "        np.random.shuffle(random_ind) # random row index\n",
    "\n",
    "        rmse_ = []\n",
    "#         rmse_elastic = []\n",
    "\n",
    "        for i, inds in enumerate(np.array_split(random_ind, cv)):\n",
    "            # split test-train\n",
    "            X_test = data.loc[data.index.isin(inds), data.columns[:X_train.shape[1]]]\n",
    "            X_train = data.loc[~data.index.isin(inds), data.columns[:X_train.shape[1]]]\n",
    "            y_test = data.loc[data.index.isin(inds)].response\n",
    "            y_train = data.loc[~data.index.isin(inds)].response\n",
    "            X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = .5)\n",
    "            # predict\n",
    "            pred = self.ensamble_model_fit_predict(X_train, y_train, X_val, y_val, X_test)\n",
    "            \n",
    "            rmse_.append(self.rmse_calc(y_test, pred))\n",
    "#             rmse_elastic.append(self.rmse_calc(y_test, pred_elastic))\n",
    "            \n",
    "            #, np.mean(rmse_elastic)\n",
    "        return np.mean(rmse_)\n",
    "    \n",
    "    def ensamble_rmse_cv_no_val(self, X_train, y_train, cv = 10, seed = 123):\n",
    "        \"\"\"\n",
    "        Estimate ensamble's model RMSE using CV\n",
    "        \"\"\"\n",
    "        data = X_train.copy()\n",
    "        data['response'] = y_train\n",
    "\n",
    "        random_ind = data.index.tolist()\n",
    "        np.random.seed(seed)\n",
    "        np.random.shuffle(random_ind) # random row index\n",
    "\n",
    "        rmse_ = []\n",
    "#         rmse_elastic = []\n",
    "\n",
    "        for i, inds in enumerate(np.array_split(random_ind, cv)):\n",
    "            # split test-train\n",
    "            X_test = data.loc[data.index.isin(inds), data.columns[:X_train.shape[1]]]\n",
    "            X_train = data.loc[~data.index.isin(inds), data.columns[:X_train.shape[1]]]\n",
    "            y_test = data.loc[data.index.isin(inds)].response\n",
    "            y_train = data.loc[~data.index.isin(inds)].response\n",
    "#             X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = .5)\n",
    "            # predict\n",
    "            pred = self.ensamble_model_fit_predict_no_val(X_train, y_train, X_test)\n",
    "            \n",
    "            rmse_.append(self.rmse_calc(y_test, pred))\n",
    "#             rmse_elastic.append(self.rmse_calc(y_test, pred_elastic))\n",
    "            \n",
    "            #, np.mean(rmse_elastic)\n",
    "        return np.mean(rmse_)\n",
    "    \n",
    "    def ensamble_predict(self, X_train, y_train, X_test, val_frac = .1, seed = 0):\n",
    "        \"\"\"\n",
    "        Predict using ensamble model\n",
    "        \"\"\"\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = val_frac, \n",
    "                                                          random_state = seed)\n",
    "        \n",
    "        pred = self.ensamble_model_fit_predict(X_train, y_train.values.ravel(), X_val, y_val.values.ravel(), X_test)\n",
    "        \n",
    "        pred[pred > 5] = 5\n",
    "        pred[pred < 1] = 1\n",
    "        \n",
    "        return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "\n",
    "[Top](#Navigation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# X_train.drop(['set'], axis = 1, inplace = True)\n",
    "# X_test.drop(['set'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##################################\n",
    "# Add new features and Fix nulls #\n",
    "##################################\n",
    "\n",
    "## New Features\n",
    "X_train_full = new_features(X_train, X_train_dates, y_train_dates)\n",
    "X_test_full = new_features(X_test, X_test_dates, y_test_dates)\n",
    "## Fix Nulls in test and train\n",
    "X_train['set'] = 'train'\n",
    "X_test['set'] = 'test'\n",
    "all_rankings_data = X_train.append(X_test, ignore_index = True)\n",
    "# params - Note that prop_user = .9 and penalty = 1.5 got smallest RMSE using CV and Lasso for prediction...\n",
    "prop_user = .7\n",
    "penalty = 1.5\n",
    "all_rankings_data_na_fix = na_fix(all_rankings_data, prop_user, penalty, titles.title)\n",
    "X_train_na_fix = all_rankings_data_na_fix.loc[all_rankings_data.set == 'train']\n",
    "X_test_na_fix = all_rankings_data_na_fix.loc[all_rankings_data.set == 'test']\n",
    "\n",
    "X_train.drop(['set'], axis = 1, inplace = True)\n",
    "X_test.drop(['set'], axis = 1, inplace = True)\n",
    "\n",
    "X_train_full_na_fix = X_train_na_fix.drop(['set'], axis = 1).copy()\n",
    "X_test_full_na_fix = X_test_na_fix.drop(['set'], axis = 1).copy()\n",
    "\n",
    "new_features_ = [col for col in X_train_full.columns if col not in X_train_na_fix.columns]\n",
    "\n",
    "X_train_full_na_fix = pd.concat([X_train_full_na_fix.reset_index(drop = True), \n",
    "                                 X_train_full[new_features_].reset_index(drop = True)], axis = 1)\n",
    "\n",
    "X_test_full_na_fix = pd.concat([X_test_full_na_fix.reset_index(drop = True), \n",
    "                                 X_test_full[new_features_].reset_index(drop = True)], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "netflix = NetflixPrize(X_train_full_na_fix, y_train_full, X_test_full_na_fix, cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated RMSE is 0.756319\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "rmse_ = netflix.ensamble_rmse_cv(netflix.X_train, netflix.y_train, seed = 111)\n",
    "end = time.time()\n",
    "print (\"Estimated RMSE is %f\" % rmse_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.349937832355499"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(end - start) / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# no validation!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated RMSE is 0.786041\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "rmse_ = netflix.ensamble_rmse_cv_no_val(netflix.X_train, netflix.y_train, seed = 111, cv = 5)\n",
    "end = time.time()\n",
    "print (\"Estimated RMSE is %f\" % rmse_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.57464109659195"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(end - start) / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Nulls to 2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_simple_na_fix = X_train.replace(0, np.nan).fillna(2.5)\n",
    "X_test_simple_na_fix = X_test.replace(0, np.nan).fillna(2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_full_simple_na_fix = pd.concat([X_train_simple_na_fix.reset_index(drop = True), \n",
    "                                 X_train_full[new_features_].reset_index(drop = True)], axis = 1)\n",
    "\n",
    "X_test_full_simple_na_fix = pd.concat([X_test_simple_na_fix.reset_index(drop = True), \n",
    "                                 X_test_full[new_features_].reset_index(drop = True)], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated RMSE is 0.758576\n"
     ]
    }
   ],
   "source": [
    "netflix = NetflixPrize(X_train_full_simple_na_fix, y_train_full, X_test_full_simple_na_fix, cv = 5)\n",
    "start = time.time()\n",
    "rmse_ = netflix.ensamble_rmse_cv(netflix.X_train, netflix.y_train, seed = 111, cv = 10)\n",
    "end = time.time()\n",
    "print (\"Estimated RMSE is %f\" % rmse_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.9938162167867"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(end - start) / 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction\n",
    "\n",
    "[Top](#Navigation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "netflix = NetflixPrize(X_train_full_na_fix, y_train_full, X_test_full_na_fix)\n",
    "predictions = pd.DataFrame()\n",
    "\n",
    "for i in range(10):\n",
    "    print (i + 1)\n",
    "    pred = netflix.ensamble_predict(X_train_full_na_fix, y_train_full, X_test_full_na_fix, \n",
    "                                    val_frac = .1, seed = i * 10)\n",
    "    predictions['pred_%d' % i] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_0</th>\n",
       "      <th>pred_1</th>\n",
       "      <th>pred_2</th>\n",
       "      <th>pred_3</th>\n",
       "      <th>pred_4</th>\n",
       "      <th>pred_5</th>\n",
       "      <th>pred_6</th>\n",
       "      <th>pred_7</th>\n",
       "      <th>pred_8</th>\n",
       "      <th>pred_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.952079</td>\n",
       "      <td>4.867215</td>\n",
       "      <td>4.894441</td>\n",
       "      <td>4.958005</td>\n",
       "      <td>4.999203</td>\n",
       "      <td>4.966142</td>\n",
       "      <td>4.941522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.928665</td>\n",
       "      <td>4.840012</td>\n",
       "      <td>4.938594</td>\n",
       "      <td>4.964162</td>\n",
       "      <td>4.991737</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.952844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.103100</td>\n",
       "      <td>3.061178</td>\n",
       "      <td>2.991971</td>\n",
       "      <td>3.099341</td>\n",
       "      <td>3.123689</td>\n",
       "      <td>3.020493</td>\n",
       "      <td>3.111426</td>\n",
       "      <td>3.129096</td>\n",
       "      <td>3.047231</td>\n",
       "      <td>3.139464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.141898</td>\n",
       "      <td>3.142936</td>\n",
       "      <td>3.054900</td>\n",
       "      <td>3.183184</td>\n",
       "      <td>3.161547</td>\n",
       "      <td>3.143621</td>\n",
       "      <td>3.150226</td>\n",
       "      <td>3.225303</td>\n",
       "      <td>3.171621</td>\n",
       "      <td>3.201327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.282169</td>\n",
       "      <td>3.247648</td>\n",
       "      <td>3.212739</td>\n",
       "      <td>3.287590</td>\n",
       "      <td>3.237950</td>\n",
       "      <td>3.263518</td>\n",
       "      <td>3.248741</td>\n",
       "      <td>3.317130</td>\n",
       "      <td>3.264996</td>\n",
       "      <td>3.291744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.192280</td>\n",
       "      <td>3.205716</td>\n",
       "      <td>3.222601</td>\n",
       "      <td>3.176503</td>\n",
       "      <td>3.188028</td>\n",
       "      <td>3.179415</td>\n",
       "      <td>3.169375</td>\n",
       "      <td>3.238943</td>\n",
       "      <td>3.270742</td>\n",
       "      <td>3.259645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.252724</td>\n",
       "      <td>4.177751</td>\n",
       "      <td>4.218696</td>\n",
       "      <td>4.176834</td>\n",
       "      <td>4.092486</td>\n",
       "      <td>4.285128</td>\n",
       "      <td>4.192825</td>\n",
       "      <td>4.265337</td>\n",
       "      <td>4.354915</td>\n",
       "      <td>4.243898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.359318</td>\n",
       "      <td>4.305100</td>\n",
       "      <td>4.290595</td>\n",
       "      <td>4.261753</td>\n",
       "      <td>4.237532</td>\n",
       "      <td>4.137355</td>\n",
       "      <td>4.298715</td>\n",
       "      <td>4.324136</td>\n",
       "      <td>4.415197</td>\n",
       "      <td>4.233309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.478512</td>\n",
       "      <td>3.474535</td>\n",
       "      <td>3.494546</td>\n",
       "      <td>3.464010</td>\n",
       "      <td>3.472875</td>\n",
       "      <td>3.514889</td>\n",
       "      <td>3.464703</td>\n",
       "      <td>3.507856</td>\n",
       "      <td>3.562883</td>\n",
       "      <td>3.483843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.963990</td>\n",
       "      <td>2.936081</td>\n",
       "      <td>2.874806</td>\n",
       "      <td>2.957390</td>\n",
       "      <td>3.014482</td>\n",
       "      <td>2.810710</td>\n",
       "      <td>2.910603</td>\n",
       "      <td>3.014055</td>\n",
       "      <td>2.933609</td>\n",
       "      <td>3.000782</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     pred_0    pred_1    pred_2    pred_3    pred_4    pred_5    pred_6  \\\n",
       "0  5.000000  5.000000  5.000000  4.952079  4.867215  4.894441  4.958005   \n",
       "1  5.000000  5.000000  5.000000  4.928665  4.840012  4.938594  4.964162   \n",
       "2  3.103100  3.061178  2.991971  3.099341  3.123689  3.020493  3.111426   \n",
       "3  3.141898  3.142936  3.054900  3.183184  3.161547  3.143621  3.150226   \n",
       "4  3.282169  3.247648  3.212739  3.287590  3.237950  3.263518  3.248741   \n",
       "5  3.192280  3.205716  3.222601  3.176503  3.188028  3.179415  3.169375   \n",
       "6  4.252724  4.177751  4.218696  4.176834  4.092486  4.285128  4.192825   \n",
       "7  4.359318  4.305100  4.290595  4.261753  4.237532  4.137355  4.298715   \n",
       "8  3.478512  3.474535  3.494546  3.464010  3.472875  3.514889  3.464703   \n",
       "9  2.963990  2.936081  2.874806  2.957390  3.014482  2.810710  2.910603   \n",
       "\n",
       "     pred_7    pred_8    pred_9  \n",
       "0  4.999203  4.966142  4.941522  \n",
       "1  4.991737  5.000000  4.952844  \n",
       "2  3.129096  3.047231  3.139464  \n",
       "3  3.225303  3.171621  3.201327  \n",
       "4  3.317130  3.264996  3.291744  \n",
       "5  3.238943  3.270742  3.259645  \n",
       "6  4.265337  4.354915  4.243898  \n",
       "7  4.324136  4.415197  4.233309  \n",
       "8  3.507856  3.562883  3.483843  \n",
       "9  3.014055  2.933609  3.000782  "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_pred = predictions.mean(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean_pred.to_csv(\"Data/Prediction_26_4.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ggplot(y_train_full, aes('V1')) + geom_density()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ToDo\n",
    "\n",
    "- Reapet and avg ?"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
